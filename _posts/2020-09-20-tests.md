In this post we will learn how to build a simple neural network in PyTorch and also how to train it
to classify images of handwritten digits in a very common dataset called MNIST.

Specifically in this tutorial we will:
* Load the  MNIST dataset
* Build a simple fully connected neural network in PyTorch
* See how to train this network
* Check the accuracy of our network on training data and testing data

### Imports
First we need will need a couple of different packages


https://gist.github.com/2337d707cf0ae7056050526b39cad135

For loading the classical dataset [MNIST](https://pytorch.org/docs/stable/torchvision/datasets.html#mnist) we need the following packages
from PyTorch we can do this using torchvision as follows


https://gist.github.com/83985837f3a1082bff6a38382d1a2142

Note that `torchvision.datasets` contains many more "standard datasets" that you may want to play
around with as well,
such as [CIFAR-10](https://pytorch.org/docs/stable/torchvision/datasets.html#cifar) and [SVHN](https://pytorch.org/docs/stable/torchvision/datasets.html#svhn) which can easily be loaded into PyTorch.  

### Loading the data
In this tutorial we use `torchvision.datasets` to load the data and if you are starting out learning deep
learning they provide several datasets you can start working with to learn modelling and training before you dive into 
custom datasets. The following lines are all that's needed to load the MNIST train and test data.


https://gist.github.com/6fa43fd6492417e4f40e5b3175d90f6f

The `train_dataset` and `test_dataset` are `Torchvision` dataset objects and in this example the only transform we apply to the images and labels is to convert them to PyTorch tensors with `transforms.ToTensor()`. The `DataLoader()` returns an iterator which will generate batches of the selected batch_size as tuples of `(data, labels)`. The argument shuffle determines whether these batches will be shuffled and you can default to setting it to true if your specific use case does not suggest otherwise. New batches will then be randomly selected each epoch which makes sure the batches are representative of the data and that the gradients in each epoch are different.